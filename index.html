<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>XELINTEL — VP of AI Interview Reference</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
</head>
<body>

    <!-- SECTION TABS -->
    <nav id="sectionTabs">
        <button class="section-tab active" data-section="intro">PROFILE</button>
        <button class="section-tab" data-section="strategy">STRATEGY</button>
        <button class="section-tab" data-section="coe">COE</button>
        <button class="section-tab" data-section="adoption">ADOPTION</button>
        <button class="section-tab" data-section="technical">TECHNICAL</button>
        <button class="section-tab" data-section="behavioral">BEHAVIORAL</button>
        <button class="section-tab" data-section="questions">QUESTIONS</button>
        <button class="section-tab" data-section="comp">COMP</button>
        <div class="search-box">
            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg>
            <input type="text" id="searchInput" placeholder="Search... (Ctrl+K)" autocomplete="off">
        </div>
    </nav>

    <!-- SUB-TOPIC PILLS -->
    <nav id="subtopicBar"></nav>

    <!-- CONTENT PANEL -->
    <main id="contentPanel">

        <!-- ═══════════════════════════════════
             TAB 1: INTRO
             ═══════════════════════════════════ -->

        <article class="topic-content" data-section="intro" data-topic="intro-background" data-label="Background">
            <h3 class="section-label">Enterprise AI Transformation</h3>
            <ul>
                <li>Led <strong>enterprise-scale AI transformation</strong> across major healthcare providers, Pharmacy Benefit Managers (PBMs), healthcare tech firms, and supply chain organizations</li>
                <li>Experience working with large enterprises including <strong>McKesson, Express Scripts, UnitedHealthcare, Cigna</strong>, as well as industrial manufacturing and financial services organizations</li>
                <li>Focus on <strong>operationalizing AI</strong> — building durable enterprise capability and measurable business outcomes, not experimentation</li>
            </ul>
            <h3 class="section-label">Microsoft & Revenue-Generating AI</h3>
            <ul>
                <li>At Microsoft, partnered with <strong>CXO and product leadership</strong> to design and scale customer-facing, revenue-generating AI platforms</li>
                <li>Deployed to <strong>millions of users</strong>, generating tens of millions in recurring value</li>
                <li>Led initiatives end-to-end: <strong>enterprise strategy → product vision → MVP → production scale → adoption → cost and performance optimization</strong></li>
            </ul>
            <h3 class="section-label">Data & Platform Foundation</h3>
            <ul>
                <li>Led large-scale <strong>data and digital transformation programs</strong> enabling AI-ready data platforms, governed data, and enterprise analytics at scale</li>
                <li>Background in <strong>enterprise platform engineering and product development</strong>, including consolidation of complex ERP ecosystems (Oracle, SAP, multi-system integration)</li>
                <li>Foundation in <strong>mission-critical, enterprise-grade systems</strong></li>
                <li>Consistent focus on <strong>scaling platforms, driving adoption</strong>, and translating advanced technology into enterprise value and competitive advantage</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Enterprise-scale AI transformation</mark></li>
                    <li><mark>Operationalizing AI at scale</mark></li>
                    <li><mark>Customer-facing, revenue-generating AI</mark></li>
                    <li><mark>CXO-level strategy and product partnership</mark></li>
                    <li><mark>Production AI deployed to millions</mark></li>
                    <li><mark>Measurable enterprise value and margin impact</mark></li>
                    <li><mark>Cross-industry enterprise transformation</mark></li>
                    <li><mark>Healthcare, supply chain, manufacturing, financial services</mark></li>
                    <li><mark>Enterprise AI platform, not point solutions</mark></li>
                    <li><mark>AI as a core business capability</mark></li>
                    <li><mark>Data foundation + governance by design</mark></li>
                    <li><mark>Mission-critical, enterprise-grade systems</mark></li>
                    <li><mark>Durable, repeatable, scalable transformation</mark></li>
                    <li><mark>Strategy, execution, and value realization</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="intro" data-topic="intro-mckesson" data-label="McKesson">
            <h3 class="section-label">Context & Mandate</h3>
            <ul>
                <li><strong>Global healthcare supply chain</strong> and distribution leader — complex multi-business data landscape</li>
                <li>Margin pressure and operational variability — AI initiatives existed but <strong>fragmented</strong></li>
                <li>Mandate: Move from experimentation → <strong>structured AI capability</strong>; strengthen supply chain intelligence and forecasting</li>
                <li>AI's power to <strong>save time, increase productivity</strong>, and <strong>streamline processes</strong> across the supply chain</li>
                <li>Provide <strong>real-time data to improve outcomes</strong> — demand signals, inventory optimization, fulfillment accuracy</li>
                <li>Enhance <strong>customer experience</strong> and enable focus on <strong>direct patient care</strong> by automating operational complexity with AI</li>
            </ul>
            <h3 class="section-label">My Role & Actions</h3>
            <ul>
                <li>Partnered with <strong>enterprise IT, digital, and product leadership</strong> to define AI CoE structure and governance model</li>
                <li>Shifted mindset from <strong>pilots → enterprise AI capability</strong>; aligned business, data, and platform teams</li>
                <li>Established <strong>hub-and-spoke AI CoE model</strong> with governance by design</li>
                <li>Prioritized <strong>high-value supply chain use cases</strong> and operationalized AI in core workflows</li>
            </ul>
            <h3 class="section-label">Impact</h3>
            <ul>
                <li>Elevated AI from analytics → <strong>strategic supply chain capability</strong></li>
                <li>Improved <strong>demand forecasting and supply visibility</strong></li>
                <li>Reduced <strong>operational inefficiencies</strong></li>
                <li>Positioned AI as <strong>margin protection and operational intelligence</strong> lever</li>
            </ul>
            <h3 class="section-label">Most Challenging & How I Navigated</h3>
            <ul>
                <li>Organizational resistance from traditional operations teams; low trust in AI-driven decisions; fragmented data ownership</li>
                <li>Secured <strong>executive sponsorship</strong>; delivered early measurable wins</li>
                <li>Positioned AI as <strong>decision augmentation, not replacement</strong></li>
                <li>Strengthened governance to <strong>build trust</strong></li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Enterprise AI in mission-critical supply chain</mark></li>
                    <li><mark>Margin protection through AI</mark></li>
                    <li><mark>Operational intelligence at scale</mark></li>
                    <li><mark>Adoption driven by trust and governance</mark></li>
                </ul>
                <h4>Measurable Outcomes</h4>
                <ul>
                    <li><mark>15–20% improvement in demand forecast accuracy</mark></li>
                    <li><mark>Reduced stockout and overstock incidents</mark></li>
                    <li><mark>$M+ in margin recovery from supply chain optimization</mark></li>
                    <li><mark>AI CoE stood up in &lt;6 months with governance framework</mark></li>
                    <li><mark>3 high-value use cases moved from pilot to production</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="intro" data-topic="intro-mdanderson" data-label="MD Anderson">
            <h3 class="section-label">Context & Mandate</h3>
            <ul>
                <li><strong>Leading academic medical center</strong> — highly regulated clinical + research environment</li>
                <li>Sensitive patient data and strict compliance — AI innovation desired but required <strong>strong governance</strong></li>
                <li>Mandate: Enable <strong>responsible AI innovation</strong>; build AI-ready data platform; support research and clinical AI initiatives</li>
            </ul>
            <h3 class="section-label">My Role & Actions</h3>
            <ul>
                <li>Worked with <strong>executive leadership, CIO org, and data teams</strong> to shape enterprise AI strategy and roadmap</li>
                <li>Balanced <strong>innovation with compliance and governance</strong></li>
                <li>Designed <strong>AI-ready governed data foundation</strong> with Responsible AI and compliance guardrails</li>
                <li>Structured <strong>enterprise AI governance model</strong>; enabled secure, compliant experimentation</li>
                <li>Helped transition <strong>research pilots → scalable capability</strong></li>
            </ul>
            <h3 class="section-label">Impact</h3>
            <ul>
                <li>Accelerated <strong>responsible AI adoption</strong></li>
                <li>Improved <strong>clinical insight capabilities</strong> and strengthened research productivity</li>
                <li>Positioned AI as <strong>core clinical and research enabler</strong></li>
            </ul>
            <h3 class="section-label">Most Challenging & How I Navigated</h3>
            <ul>
                <li>Regulatory and compliance complexity; data sensitivity and privacy constraints; cultural resistance in clinical workflows</li>
                <li><strong>Governance-first approach</strong> with clear ownership and accountability</li>
                <li>Strong executive alignment; positioned AI as <strong>augmenting clinical decision-making</strong></li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Responsible AI in regulated healthcare</mark></li>
                    <li><mark>Governance by design</mark></li>
                    <li><mark>Clinical-grade AI readiness</mark></li>
                    <li><mark>Secure enterprise data platform</mark></li>
                </ul>
                <h4>Measurable Outcomes</h4>
                <ul>
                    <li><mark>Governed data platform serving 50+ research teams</mark></li>
                    <li><mark>40% faster data access for clinical AI initiatives</mark></li>
                    <li><mark>Responsible AI framework adopted institution-wide</mark></li>
                    <li><mark>3 research pilots transitioned to scalable production</mark></li>
                    <li><mark>Full HIPAA/IRB-compliant AI experimentation pipeline</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="intro" data-topic="intro-uhc" data-label="UnitedHealthcare">
            <h3 class="section-label">Context & Mandate</h3>
            <ul>
                <li><strong>Large payer with massive data scale</strong> — complex claims, risk, and operations landscape</li>
                <li>Need for <strong>cost efficiency and operational intelligence</strong>; digital and customer engagement transformation</li>
                <li>Mandate: Improve operational intelligence and automation; strengthen digital and customer-facing AI; align AI with <strong>measurable business outcomes</strong></li>
            </ul>
            <h3 class="section-label">My Role & Actions</h3>
            <ul>
                <li>Strategic advisor to <strong>data, digital, and platform leadership</strong>; bridged business, data, and AI platform teams</li>
                <li>Prioritized <strong>high-ROI AI use cases</strong> (claims, risk, engagement)</li>
                <li>Introduced <strong>platform-based AI architecture</strong> (RAG, governed AI)</li>
                <li>Strengthened <strong>governance and lifecycle discipline</strong>; focused on operationalizing AI at scale</li>
            </ul>
            <h3 class="section-label">Impact</h3>
            <ul>
                <li>Improved <strong>operational efficiency and automation</strong></li>
                <li>Enhanced <strong>customer engagement capability</strong></li>
                <li>Reduced cost through <strong>AI-driven insights</strong></li>
                <li>Positioned AI as <strong>core business capability, not experimentation</strong></li>
            </ul>
            <h3 class="section-label">Most Challenging & How I Navigated</h3>
            <ul>
                <li>Enterprise complexity and scale; balancing innovation with operational reliability; aligning business and technology priorities</li>
                <li>Focused on <strong>high-ROI use cases</strong> with clear prioritization framework</li>
                <li>Simplified <strong>architecture and execution path</strong></li>
                <li>Ensured alignment between <strong>business and platform teams</strong></li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>AI at payer-scale enterprise</mark></li>
                    <li><mark>Automation + operational intelligence</mark></li>
                    <li><mark>Business-aligned AI transformation</mark></li>
                    <li><mark>Scalable, governed AI platform</mark></li>
                </ul>
                <h4>Measurable Outcomes</h4>
                <ul>
                    <li><mark>30% reduction in claims processing cycle time</mark></li>
                    <li><mark>$M+ annual savings from AI-driven automation</mark></li>
                    <li><mark>5 high-ROI use cases delivered in first year</mark></li>
                    <li><mark>Improved member engagement scores through AI personalization</mark></li>
                    <li><mark>Platform-based architecture reduced time-to-deploy by 60%</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="intro" data-topic="intro-msft" data-label="Microsoft SC">
            <h3 class="section-label">Context & Mandate</h3>
            <ul>
                <li><strong>Large internal supply chain ecosystem</strong> — complex cross-functional environment</li>
                <li>Need for improved <strong>operational intelligence and optimization</strong></li>
                <li>Mandate: Strengthen AI-driven supply chain intelligence; improve forecasting, efficiency, and decision-making; build <strong>internal AI capability and adoption</strong></li>
            </ul>
            <h3 class="section-label">My Role & Actions</h3>
            <ul>
                <li>Shaped <strong>internal AI approach for supply chain optimization</strong>; worked across engineering, data, and business teams</li>
                <li>Introduced <strong>AI-driven forecasting and optimization</strong> approaches</li>
                <li>Strengthened <strong>data and platform alignment</strong>; focused on scaling adoption across workflows</li>
                <li>Improved <strong>lifecycle and operational discipline</strong></li>
            </ul>
            <h3 class="section-label">Impact</h3>
            <ul>
                <li>Improved <strong>forecasting accuracy and supply visibility</strong></li>
                <li>Reduced <strong>inefficiencies and operational variability</strong></li>
                <li>Strengthened <strong>internal AI capability</strong></li>
                <li>Demonstrated <strong>enterprise AI in operational supply chain</strong></li>
            </ul>
            <h3 class="section-label">Most Challenging & How I Navigated</h3>
            <ul>
                <li>Cross-functional alignment; adoption across operational teams; data consistency and integration</li>
                <li>Built <strong>strong cross-team alignment</strong>; delivered measurable early improvements</li>
                <li>Focused on <strong>operational impact</strong> and drove disciplined execution</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Internal enterprise AI transformation</mark></li>
                    <li><mark>Operational intelligence through AI</mark></li>
                    <li><mark>Cross-functional execution</mark></li>
                    <li><mark>Scaling adoption across workflows</mark></li>
                </ul>
                <h4>Measurable Outcomes</h4>
                <ul>
                    <li><mark>20%+ improvement in forecast accuracy</mark></li>
                    <li><mark>Reduced supply chain variability across key product lines</mark></li>
                    <li><mark>AI adoption scaled to 4+ operational workflows</mark></li>
                    <li><mark>Cross-functional alignment across engineering, data, and ops</mark></li>
                    <li><mark>Measurable cost savings from reduced inefficiencies</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="intro" data-topic="intro-leadership" data-label="Leadership">
            <h3 class="section-label">Leadership Philosophy</h3>
            <ul>
                <li>Lead through <strong>clarity and alignment</strong> — make the complex simple for senior leaders</li>
                <li>Build organizations where <strong>strategy and execution are not separate</strong></li>
                <li>Drive impact through <strong>influence, not just authority</strong></li>
                <li>Create environments where teams can <strong>move fast with guardrails</strong></li>
            </ul>
            <h3 class="section-label">Decision Style</h3>
            <ul>
                <li>Data-informed, not data-paralyzed — <strong>decide with 70% information</strong></li>
                <li>Balance speed with governance — <strong>fast doesn't mean reckless</strong></li>
                <li>Set clear decision rights — <strong>who decides, who advises, who is informed</strong></li>
            </ul>
            <h3 class="section-label">Executive Presence</h3>
            <ul>
                <li>Translate technical complexity into <strong>business language</strong></li>
                <li>Command rooms through <strong>preparation, clarity, and conviction</strong></li>
                <li>Build trust with C-suite through <strong>credibility + follow-through</strong></li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Lead through clarity and alignment</mark></li>
                    <li><mark>Balance speed with governance</mark></li>
                    <li><mark>Influence without authority</mark></li>
                    <li><mark>Simplify complexity for leaders</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="intro" data-topic="intro-fit" data-label="Fit">
            <h3 class="section-label">Why Move from Consulting → Industry</h3>
            <ul>
                <li>Intentional shift from <strong>advisory → ownership and execution</strong></li>
                <li>Desire to <strong>build and scale durable enterprise AI capability</strong>, not just shape direction</li>
                <li>Have repeatedly helped organizations move from <strong>strategy → MVP → production → scale</strong>, now want full accountability for outcomes</li>
                <li>Industry role enables <strong>long-term value creation, operational impact, and sustained transformation</strong></li>
                <li>Move aligns with where AI is today — <strong>from experimentation to enterprise operationalization</strong></li>
                <li>Motivated by building <strong>platform, adoption, and measurable business value at scale</strong></li>
            </ul>
            <h3 class="section-label">Why I Am the Right Hire <em>Now</em></h3>
            <ul>
                <li>Deep experience helping large enterprises <strong>operationalize AI, not just experiment</strong></li>
                <li>Proven ability to work with <strong>CXO leadership across strategy, platform, adoption, and value realization</strong></li>
                <li>Experience across <strong>AI CoE, governance, platform, and enterprise adoption</strong> — full lifecycle</li>
                <li>Background across healthcare, supply chain, and regulated environments — <strong>relevant to enterprise complexity</strong></li>
                <li>Balanced profile: <strong>strategy + technical depth + execution discipline + adoption focus</strong></li>
                <li>Understand how to move from <strong>pilot → production → enterprise scale</strong></li>
                <li>Ready to deliver impact immediately — not learning, but scaling</li>
            </ul>
            <h3 class="section-label">Closing Positioning Cue</h3>
            <ul>
                <li>The opportunity now is to <strong>operationalize AI at enterprise scale</strong>, and my experience aligns directly with building governed, scalable, and value-driven AI capability</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Moving from advising to owning outcomes</mark></li>
                    <li><mark>From shaping direction to building capability</mark></li>
                    <li><mark>Long-term enterprise transformation</mark></li>
                    <li><mark>Execution with accountability</mark></li>
                    <li><mark>Durable and scalable impact</mark></li>
                    <li><mark>Operationalizing AI at scale</mark></li>
                    <li><mark>Built and operationalized enterprise AI</mark></li>
                    <li><mark>Strategy, platform, adoption, and value — full lifecycle</mark></li>
                    <li><mark>Proven at enterprise scale</mark></li>
                    <li><mark>Ready to execute from day one</mark></li>
                    <li><mark>Bridge between business, technology, and transformation</mark></li>
                    <li><mark>Scaled AI in complex, regulated environments</mark></li>
                    <li><mark>Move organizations from pilots to platforms</mark></li>
                </ul>
            </div>
        </article>

        <!-- ═══════════════════════════════════
             TAB 2: STRATEGY
             ═══════════════════════════════════ -->

        <article class="topic-content" data-section="strategy" data-topic="strategy-vision" data-label="Vision">
            <h3 class="section-label">Core Vision Statement</h3>
            <ul>
                <li><strong>"AI becomes the enterprise intelligence layer that makes Cardinal Health's supply chain more predictable, more resilient, and more efficient — every single day."</strong></li>
            </ul>
            <h3 class="section-label">Talking Points</h3>
            <ul>
                <li>Cardinal Health operates <strong>one of the most complex, regulated, data-intensive healthcare supply chains</strong> in the country — AI must work at enterprise scale, not as isolated pilots</li>
                <li>The goal is <strong>human-led, AI-operated</strong> systems: AI handles optimization and prediction; humans retain judgment, accountability, and trust</li>
                <li>AI is not a digital overlay — it is the <strong>decision layer</strong> embedded into how inventory, demand, fulfillment, pricing, and service operate every day</li>
            </ul>
            <h3 class="section-label">One-Line Close</h3>
            <ul>
                <li><strong>"My strategy is simple: make AI a trusted operating capability — embedded in Cardinal Health's core workflows — so reliability improves, costs fall, and decisions get faster at enterprise scale."</strong></li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Enterprise intelligence layer</mark></li>
                    <li><mark>Human-led. AI-operated. Enterprise-scaled.</mark></li>
                    <li><mark>From reactive execution to predictive, resilient operations</mark></li>
                    <li><mark>AI as a core operating capability, not a side program</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="strategy" data-topic="strategy-focus" data-label="Focus">
            <h3 class="section-label">Focus 1: Core Business Processes</h3>
            <ul>
                <li>AI-operated, human-supervised systems for <strong>demand forecasting, inventory optimization, routing, and pricing</strong></li>
                <li>Shift teams from managing dashboards to <strong>managing exceptions</strong></li>
                <li><strong>"AI runs the flow; humans manage the edge cases."</strong></li>
            </ul>
            <h3 class="section-label">Focus 2: Employees & Customers</h3>
            <ul>
                <li>Embed <strong>AI copilots and domain-specific agents</strong> directly into workflows for planners, operators, finance, and customer teams</li>
                <li>Move customer engagement from reactive issue handling to <strong>proactive, predictive alerts</strong> with GenAI explanations grounded in governed data (RAG)</li>
                <li><strong>"Decision intelligence at the point of action."</strong></li>
            </ul>
            <h3 class="section-label">Focus 3: AI CoE & Platform</h3>
            <ul>
                <li>Lead a <strong>central AI CoE</strong> that turns pilots into platforms — shared data foundations, reusable features, reusable models</li>
                <li>Establish disciplined <strong>MLOps, model governance, drift monitoring, and security by design</strong> to scale responsibly</li>
                <li><strong>"From experiments to an AI factory."</strong></li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>AI runs the flow; humans manage the edge cases</mark></li>
                    <li><mark>Decision intelligence at the point of action</mark></li>
                    <li><mark>From experiments to an AI factory</mark></li>
                    <li><mark>Scale before sophistication</mark></li>
                    <li><mark>Platform economics — reuse compounds value</mark></li>
                    <li><mark>Governance is an enabler, not a brake</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="strategy" data-topic="strategy-value" data-label="Value">
            <h3 class="section-label">Value 1: Reliability & Resilience</h3>
            <ul>
                <li>Better demand sensing and inventory positioning <strong>reduce volatility and disruptions</strong></li>
                <li>Digital twins and scenario modeling improve <strong>response to shocks and shortages</strong></li>
                <li><strong>"AI bends variability out of the system."</strong></li>
            </ul>
            <h3 class="section-label">Value 2: Cost-to-Serve & Working Capital</h3>
            <ul>
                <li>Less waste, fewer expedites, reduced manual rework, <strong>optimized inventory turns</strong></li>
                <li>AI improves <strong>margin protection</strong> without sacrificing service levels</li>
                <li><strong>"Lower cost-to-serve without lower service."</strong></li>
            </ul>
            <h3 class="section-label">Value 3: Speed & Trust</h3>
            <ul>
                <li>GenAI translates complex optimization logic into <strong>explainable, actionable guidance</strong> leaders can trust</li>
                <li>Built-in governance ensures AI is <strong>secure, auditable, SOX-aligned, and compliant</strong> from day one</li>
                <li><strong>"Faster decisions, higher confidence."</strong></li>
            </ul>
            <h3 class="section-label">Executive Value Summary</h3>
            <ul>
                <li><strong>"The VP of AI role exists to deliver reliability, cost efficiency, and speed — while earning enterprise trust at scale."</strong></li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>AI bends variability out of the system</mark></li>
                    <li><mark>Lower cost-to-serve without lower service</mark></li>
                    <li><mark>Faster decisions, higher confidence</mark></li>
                    <li><mark>Reliability, cost efficiency, and speed</mark></li>
                    <li><mark>Enterprise trust at scale</mark></li>
                </ul>
            </div>
        </article>

        <!-- ═══════════════════════════════════
             TAB 3: COE
             ═══════════════════════════════════ -->

        <article class="topic-content" data-section="coe" data-topic="coe-model" data-label="Model">
            <h3 class="section-label">Reference Points</h3>
            <ul>
                <li><strong>Hub-and-spoke AI CoE</strong> — central platform + federated domain execution</li>
                <li>CoE owns <strong>platform, standards, governance, and reusable capability</strong></li>
                <li>Business units own <strong>use cases and value realization</strong></li>
                <li>Focus on <strong>platform, not projects</strong> — reusable data, models, pipelines</li>
                <li>Build <strong>AI factory model</strong> — idea → prioritization → build → deploy → scale</li>
                <li>Cross-functional: <strong>business, data, engineering, governance, security</strong></li>
                <li>Balance <strong>central control with domain autonomy</strong></li>
                <li>Start with <strong>high-value lighthouse use cases</strong>, then scale horizontally</li>
            </ul>
            <h3 class="section-label">If They Ask: "How would you structure the CoE at Cardinal?"</h3>
            <ul>
                <li>I'd start by <strong>assessing the current state</strong> — what exists, what's working, where the gaps are. Then I'd design a hub-and-spoke model where the central team owns platform, governance, and reusable capability, while business units own use case execution and value realization. The key is making the CoE a <strong>force multiplier, not a bottleneck</strong>. I'd begin with 2–3 lighthouse use cases in supply chain or operations, prove the model, then scale the pattern horizontally across the enterprise.</li>
                <li>The CoE also needs to be <strong>cross-functional from day one</strong> — data, engineering, governance, security, and business all at the table. At Cardinal, given the complexity of supply chain and regulatory requirements, governance has to be embedded from the start, not layered on later.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Hub-and-spoke operating model</mark></li>
                    <li><mark>Platform over projects</mark></li>
                    <li><mark>AI factory model</mark></li>
                    <li><mark>Reusable enterprise capability</mark></li>
                    <li><mark>Federated execution with central standards</mark></li>
                    <li><mark>Business owns value, CoE enables scale</mark></li>
                    <li><mark>Durable and scalable AI capability</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="coe" data-topic="coe-governance" data-label="Governance">
            <h3 class="section-label">Reference Points</h3>
            <ul>
                <li><strong>Governance by design</strong>, not after deployment</li>
                <li>Clear <strong>model ownership, accountability, and lifecycle control</strong></li>
                <li>Responsible AI: <strong>fairness, transparency, explainability, auditability</strong></li>
                <li>Risk management embedded across lifecycle (<strong>build → deploy → operate</strong>)</li>
                <li>Strong <strong>data governance + access + lineage + security</strong></li>
                <li>Guardrails <strong>enable scale</strong>, not barriers to innovation</li>
                <li>Align with <strong>regulatory and compliance requirements</strong> (healthcare, enterprise)</li>
                <li>Monitor models: <strong>performance, drift, cost, usage, risk</strong></li>
            </ul>
            <h3 class="section-label">If They Ask: "How do you handle AI governance in a regulated environment?"</h3>
            <ul>
                <li>In healthcare, governance isn't optional — it's the <strong>license to operate</strong>. I treat governance as a day-one design requirement, not a compliance checkpoint. That means every model has a <strong>clear owner, a risk tier, documented lineage, and monitoring in place</strong> before it goes to production. I've done this at MD Anderson in a HIPAA-regulated environment and at McKesson where supply chain decisions directly impact patient safety.</li>
                <li>The key insight is that <strong>governance enables speed, not the opposite</strong>. When teams trust the guardrails, they move faster because they're not afraid of compliance surprises. I also ensure governance scales — lightweight for low-risk use cases, rigorous for anything touching clinical data, pricing, or patient-facing decisions.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Governance by design</mark></li>
                    <li><mark>Responsible and trusted AI</mark></li>
                    <li><mark>Clear ownership and accountability</mark></li>
                    <li><mark>Guardrails, not barriers</mark></li>
                    <li><mark>Model risk management</mark></li>
                    <li><mark>Compliance-ready AI</mark></li>
                    <li><mark>Transparent and auditable AI</mark></li>
                    <li><mark>Secure, governed, production AI</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="coe" data-topic="coe-portfolio" data-label="Portfolio">
            <h3 class="section-label">Reference Points</h3>
            <ul>
                <li><strong>Value-driven portfolio</strong>, not tech-driven experimentation</li>
                <li>Prioritize based on <strong>business impact, feasibility, and scalability</strong></li>
                <li>Fund <strong>lighthouse use cases</strong> → scale proven patterns</li>
                <li>Clear <strong>business case and ROI framework</strong> for AI investments</li>
                <li>Kill low-value pilots early, <strong>double down on scalable impact</strong></li>
                <li>Balance <strong>innovation vs operational value</strong></li>
                <li>Portfolio governance ensures <strong>alignment with enterprise strategy</strong></li>
                <li>Measure outcomes: <strong>revenue, cost, productivity, risk, adoption</strong></li>
            </ul>
            <h3 class="section-label">If They Ask: "How do you decide what to fund and what to kill?"</h3>
            <ul>
                <li>I use a <strong>stage-gate approach</strong> — fund to the next proof point, not to completion. Every initiative needs a business sponsor, a measurable outcome, and a clear path to scale. If a pilot can't show value within a defined timeframe, we kill it and redeploy resources. At McKesson, I implemented quarterly portfolio reviews where every AI initiative was evaluated on business impact, adoption trajectory, and scalability — the result was fewer projects but more scaled impact.</li>
                <li>I also balance the portfolio between <strong>operational value (near-term ROI) and strategic bets (future capability)</strong>. Cardinal Health needs both — AI that protects margins today and AI that positions the company for competitive advantage tomorrow. The key is never letting innovation theater consume resources that should be driving enterprise value.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Value-backed AI portfolio</mark></li>
                    <li><mark>Fund what scales</mark></li>
                    <li><mark>Kill pilots, scale platforms</mark></li>
                    <li><mark>Business-first prioritization</mark></li>
                    <li><mark>Portfolio governance</mark></li>
                    <li><mark>Measurable enterprise outcomes</mark></li>
                    <li><mark>Innovation with discipline</mark></li>
                    <li><mark>Enterprise value realization</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="coe" data-topic="coe-pillars" data-label="Five Pillars">
            <h3 class="section-label">Five Pillars of AI Success</h3>
            <ul>
                <li>Sustainable AI success requires <strong>alignment across five interdependent pillars</strong> — not just technology</li>
                <li>Each pillar must be <strong>intentionally designed and governed</strong> to deliver enterprise-scale outcomes</li>
            </ul>

            <h3 class="section-label">1. Business Strategy</h3>
            <ul>
                <li>AI investments must be <strong>anchored to business priorities</strong> — revenue, cost, risk, experience</li>
                <li>Every AI initiative starts with a <strong>business case, not a model</strong></li>
                <li>Business strategy defines <strong>where AI creates value</strong> — supply chain optimization, demand forecasting, cost-to-serve reduction</li>
                <li>AI roadmap should be a <strong>subset of the enterprise strategy</strong>, not a parallel track</li>
            </ul>

            <h3 class="section-label">2. Technology Strategy</h3>
            <ul>
                <li>Platform decisions drive <strong>scale, reuse, and speed</strong> — cloud, data infrastructure, MLOps, integration</li>
                <li>Build a <strong>composable AI platform</strong> — shared services, APIs, reusable pipelines</li>
                <li>Align with enterprise architecture — <strong>GCP/Vertex AI, data mesh, feature stores, CI/CD for ML</strong></li>
                <li>Technology strategy must support <strong>production-grade reliability</strong>, not just experimentation</li>
            </ul>

            <h3 class="section-label">3. AI Strategy &amp; Experience</h3>
            <ul>
                <li>Define <strong>what AI does and how people experience it</strong> — UX, trust, transparency</li>
                <li>Design for <strong>human-in-the-loop</strong> where judgment matters — healthcare, compliance, pricing</li>
                <li>AI experience must be <strong>embedded in workflows</strong>, not bolted on as separate tools</li>
                <li>Strategy covers the full lifecycle: <strong>ideation → build → deploy → adopt → measure → iterate</strong></li>
            </ul>

            <h3 class="section-label">4. Org &amp; Culture</h3>
            <ul>
                <li>AI transformation is a <strong>people challenge</strong> as much as a technology one</li>
                <li>Build <strong>AI fluency across the organization</strong> — not just in the CoE</li>
                <li>Create a culture of <strong>experimentation with accountability</strong> — safe to try, expected to measure</li>
                <li>Org design matters: <strong>federated execution with centralized governance</strong></li>
                <li>Talent strategy: <strong>hire, upskill, partner</strong> — build the team the enterprise needs, not just what's available</li>
            </ul>

            <h3 class="section-label">5. AI Governance</h3>
            <ul>
                <li>Governance is the <strong>foundation, not a constraint</strong> — it enables speed at scale</li>
                <li>Cover <strong>model risk, data lineage, bias, explainability, and compliance</strong> (SOX, HIPAA, FDA)</li>
                <li>Establish <strong>tiered review</strong> — lightweight for low-risk, deep for high-impact</li>
                <li>Governance must be <strong>operationalized into workflows</strong>, not documented in binders</li>
                <li>Board-level reporting: <strong>risk posture, compliance status, value delivery</strong></li>
            </ul>

            <h3 class="section-label">If They Ask:</h3>
            <ul>
                <li><em>"How do these five pillars work together?"</em> — They are interdependent. Business strategy sets direction, technology strategy enables it, AI strategy and experience define how it's delivered, org and culture drive adoption, and governance ensures it scales responsibly. At Cardinal Health, I would align all five from day one — using the CoE as the integration point so nothing moves in isolation.</li>
                <li><em>"Which pillar is most often neglected?"</em> — Org and culture. Most enterprises invest in technology and governance but underinvest in fluency, change management, and the cultural shift required. At McKesson and Microsoft, some of the hardest work was getting supply chain operators and business leaders to trust AI-driven recommendations — that's a culture problem, not a tech problem.</li>
            </ul>

            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Five interdependent pillars</mark></li>
                    <li><mark>Business-anchored AI investments</mark></li>
                    <li><mark>Composable AI platform</mark></li>
                    <li><mark>Human-in-the-loop design</mark></li>
                    <li><mark>AI fluency across the org</mark></li>
                    <li><mark>Experimentation with accountability</mark></li>
                    <li><mark>Governance as enabler, not constraint</mark></li>
                    <li><mark>Federated execution, centralized governance</mark></li>
                    <li><mark>Full lifecycle — ideation to iteration</mark></li>
                </ul>
            </div>
        </article>

        <!-- ═══════════════════════════════════
             TAB 4: ADOPTION
             ═══════════════════════════════════ -->

        <article class="topic-content" data-section="adoption" data-topic="adoption-build" data-label="Build">
            <h3 class="section-label">Embedding AI into Workflows</h3>
            <ul>
                <li><strong>Adoption is designed, not assumed</strong> — build it into the rollout plan from day one</li>
                <li><strong>Embed AI into existing workflows</strong> — don't force new tools, meet people where they work</li>
                <li>Build <strong>AI-native workflows</strong>, not AI-adjacent bolt-ons that add friction</li>
                <li><strong>Remove friction for users</strong> — if it's harder with AI, they won't use it</li>
            </ul>
            <h3 class="section-label">Training & Enablement</h3>
            <ul>
                <li><strong>AI literacy at scale:</strong> Tiered by role — executive, manager, practitioner, citizen developer</li>
                <li>Enablement is <strong>continuous, not one-time training</strong> — build ongoing learning programs</li>
                <li>Make AI <strong>accessible, not mystical</strong> — demystify for business users</li>
            </ul>
            <h3 class="section-label">Early Wins & Momentum</h3>
            <ul>
                <li><strong>Early wins create momentum</strong> — start with high-visibility, low-risk use cases</li>
                <li>Showcase results quickly to <strong>build credibility and pull demand</strong></li>
                <li>Let success stories <strong>recruit the next wave of adopters</strong></li>
            </ul>
            <h3 class="section-label">If They Ask: "How would you drive adoption at Cardinal?"</h3>
            <ul>
                <li>Adoption at Cardinal has to be <strong>workflow-native</strong>. Supply chain planners, operators, and customer teams won't adopt AI if it means learning a new tool — it has to be embedded in the systems they already use. I'd start with <strong>2–3 high-visibility use cases</strong> — demand forecasting, inventory optimization, or customer alerts — deliver measurable wins in 90 days, then use those stories to create pull across other business units.</li>
                <li>I'd also build a <strong>tiered enablement program</strong>: executive AI literacy for leadership (what AI can and can't do), practitioner training for operational teams (how to interpret and act on AI outputs), and prompt coaching for copilot/GenAI users. The goal is making AI feel like <strong>a better version of how people already work</strong>, not a disruption.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Adoption is designed, not assumed</mark></li>
                    <li><mark>Embed AI into existing workflows</mark></li>
                    <li><mark>Remove friction for users</mark></li>
                    <li><mark>Early wins create momentum</mark></li>
                    <li><mark>AI literacy at scale</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="adoption" data-topic="adoption-resistance" data-label="Resistance">
            <h3 class="section-label">Change Management Approach</h3>
            <ul>
                <li><strong>Adoption beats technology</strong> — the best model unused is worthless</li>
                <li><strong>Change before scale:</strong> Invest in change management before rolling out enterprise-wide</li>
                <li>Resistance is <strong>natural — address fear, uncertainty, and inertia</strong> head-on</li>
                <li>Start with <strong>believers, not skeptics</strong> — build momentum through early adopters</li>
            </ul>
            <h3 class="section-label">Incentives & Alignment</h3>
            <ul>
                <li><strong>Align incentives with outcomes</strong> — tie KPIs and performance reviews to AI adoption</li>
                <li>Show <strong>what's in it for them</strong> — make AI an advantage, not a threat</li>
                <li><strong>Executive sponsorship</strong> is non-negotiable — visible leadership commitment drives behavior</li>
            </ul>
            <h3 class="section-label">Building Trust</h3>
            <ul>
                <li><strong>Trust drives adoption</strong> — people use what they understand and trust</li>
                <li>Invest in <strong>governance and explainability</strong> to build confidence across the organization</li>
                <li><strong>Governance enables scale</strong> — without guardrails, adoption stalls at the pilot stage</li>
            </ul>
            <h3 class="section-label">If They Ask: "Tell me about a time you faced resistance"</h3>
            <ul>
                <li>At McKesson, traditional operations teams were deeply skeptical of AI-driven demand forecasting — they'd been doing it manually for decades and didn't trust the models. Instead of forcing adoption top-down, I <strong>secured executive sponsorship</strong> to give it air cover, then worked with a small group of planners who were open to trying it. We ran AI recommendations <strong>alongside their existing process</strong> for 60 days — they could see when AI was right and when it wasn't. Once they saw the accuracy improvements, they became the strongest advocates. That peer influence was far more powerful than any mandate.</li>
                <li>The lesson is that <strong>resistance is a signal, not a blocker</strong>. It usually means people don't trust the output, don't understand the value, or fear being replaced. Address those three things — through governance, explainability, and positioning AI as augmentation — and resistance converts to adoption.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Adoption beats technology</mark></li>
                    <li><mark>Align incentives with outcomes</mark></li>
                    <li><mark>Trust drives adoption</mark></li>
                    <li><mark>Governance enables scale</mark></li>
                    <li><mark>Change before scale</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="adoption" data-topic="adoption-scale" data-label="Scale & Measure">
            <h3 class="section-label">Pilot → Production → Enterprise</h3>
            <ul>
                <li><strong>Scale what works</strong> — don't try to scale everything, double down on proven use cases</li>
                <li>Most organizations are <strong>stuck in POC mode</strong> — the real work starts at production</li>
                <li>Enterprise scale requires: <strong>platform, standards, repeatable patterns</strong></li>
                <li>Build a <strong>deployment playbook</strong> — every model follows the same production path</li>
            </ul>
            <h3 class="section-label">Adoption Metrics & Operationalization</h3>
            <ul>
                <li><strong>Measure usage, not deployment</strong> — a deployed model nobody uses is a failed project</li>
                <li>Track: <strong>active users, decision quality improvement, time saved, business value</strong></li>
                <li><strong>Industrialize adoption</strong> — repeatable frameworks for onboarding new use cases</li>
                <li>Operational visibility: <strong>dashboards, not slide decks</strong></li>
            </ul>
            <h3 class="section-label">Sustained Value</h3>
            <ul>
                <li><strong>Sustained value, not one-time wins</strong> — adoption must be durable, not a campaign</li>
                <li>Continuously reinforce through <strong>feedback loops, retraining, and optimization</strong></li>
                <li>Success metric shifts from <strong>"does it work?" to "does it deliver value at scale?"</strong></li>
            </ul>
            <h3 class="section-label">If They Ask: "How do you move beyond pilots?"</h3>
            <ul>
                <li>Most organizations get stuck in POC mode because they treat every AI initiative as a <strong>standalone project instead of a platform capability</strong>. The fix is building repeatable patterns — a deployment playbook, shared infrastructure, standard governance gates — so the second use case is 3x faster than the first. At UnitedHealthcare, introducing platform-based architecture reduced time-to-deploy by 60% after the first use case was live.</li>
                <li>The measurement shift is critical too. Most teams measure <strong>model deployment</strong> — did we ship it? The real metric is <strong>sustained usage and business impact</strong>. I track active users, decision quality improvement, and dollars of value delivered monthly. If usage drops, that's a product problem, not a data science problem — and we treat it that way.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Scale what works</mark></li>
                    <li><mark>Measure usage, not deployment</mark></li>
                    <li><mark>Industrialize adoption</mark></li>
                    <li><mark>Sustained value, not one-time wins</mark></li>
                </ul>
            </div>
        </article>

        <!-- ═══════════════════════════════════
             TAB 5: TECHNICAL
             ═══════════════════════════════════ -->

        <article class="topic-content" data-section="technical" data-topic="tech-rag" data-label="RAG">
            <h3 class="section-label">Retrieval Augmented Generation Architecture</h3>
            <ul>
                <li><strong>RAG pipeline:</strong> Index → Chunk → Embeddings → Vector + Semantic search → Grounded response</li>
                <li><strong>Grounded AI over hallucinated AI</strong> — enterprise GenAI must be anchored in real data</li>
                <li><strong>Enterprise data as source of truth</strong> — ground LLM responses in internal knowledge bases, not public training data</li>
                <li><strong>Retrieval before generation</strong> — fetch relevant context first, then generate the answer</li>
            </ul>
            <h3 class="section-label">When to Use RAG vs Fine-Tuning</h3>
            <ul>
                <li><strong>RAG for dynamic, evolving knowledge</strong> — documents, policies, internal data that changes frequently</li>
                <li><strong>Fine-tuning for behavioral adaptation</strong> — tone, domain-specific reasoning, specialized formats</li>
                <li>Most enterprise use cases are <strong>RAG-first</strong> — fine-tuning is the exception, not the default</li>
            </ul>
            <h3 class="section-label">Enterprise Deployment & Governance</h3>
            <ul>
                <li><strong>Controlled, auditable GenAI</strong> — every response traceable to its source documents</li>
                <li><strong>Data pipeline basics:</strong> Ingestion, chunking strategy, embedding model selection, index refresh cadence</li>
                <li><strong>Grounding & evaluation:</strong> Faithfulness scoring, citation accuracy, relevance metrics</li>
                <li><strong>RAG enables safe enterprise copilots</strong> — the architecture that makes GenAI deployable at scale</li>
                <li>Security: <strong>data boundary enforcement, access control on retrieval, PII filtering</strong></li>
            </ul>
            <h3 class="section-label">If They Ask: "How would you use RAG at Cardinal Health?"</h3>
            <ul>
                <li>Cardinal Health has massive internal knowledge — supply chain procedures, regulatory documentation, product specifications, customer contracts. RAG lets us build <strong>copilots that answer questions grounded in that real data</strong>, not hallucinated responses from a general-purpose LLM. Imagine a planner asking "What's the reorder trigger for Product X at Distribution Center Y?" and getting an accurate, cited answer in seconds instead of searching three systems.</li>
                <li>The architecture is straightforward but the <strong>data pipeline discipline is critical</strong> — chunking strategy, embedding quality, refresh cadence, and access control. In a healthcare environment, you also need <strong>PII filtering and compliance-aware retrieval</strong> so sensitive data never leaks into a response. I've built these pipelines before — the key is treating RAG as enterprise infrastructure, not a demo.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Grounded AI over hallucinated AI</mark></li>
                    <li><mark>Enterprise data as source of truth</mark></li>
                    <li><mark>Retrieval before generation</mark></li>
                    <li><mark>Controlled, auditable GenAI</mark></li>
                    <li><mark>RAG enables safe enterprise copilots</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="technical" data-topic="tech-agents" data-label="Agents">
            <h3 class="section-label">AI Agents & Multi-Agent Architecture</h3>
            <ul>
                <li><strong>Agents extend GenAI into action</strong> — from answering questions to executing multi-step tasks</li>
                <li>Core capabilities: <strong>tool use, orchestration, memory, planning</strong></li>
                <li><strong>Multi-agent systems:</strong> Specialized agents collaborate — planner, executor, reviewer, validator</li>
                <li>Enterprise automation: <strong>process orchestration, document workflows, decision support chains</strong></li>
            </ul>
            <h3 class="section-label">Guardrails & Control</h3>
            <ul>
                <li><strong>Orchestrated, not autonomous chaos</strong> — every agent operates within defined boundaries</li>
                <li><strong>Guardrails enable safe automation</strong> — scope limits, approval gates, fallback mechanisms</li>
                <li><strong>Human-in-the-loop:</strong> Critical decisions require human validation — agents recommend, humans decide</li>
                <li><strong>Human accountability remains</strong> — AI acts, humans own the outcome</li>
            </ul>
            <h3 class="section-label">Enterprise Orchestration</h3>
            <ul>
                <li>When agents are useful: <strong>repetitive multi-step tasks, complex research, workflow automation</strong></li>
                <li>Autonomous vs supervised: <strong>match autonomy level to risk level</strong> — low-risk = higher autonomy</li>
                <li>Enterprise readiness: <strong>logging, audit trails, cost controls, graceful degradation</strong></li>
            </ul>
            <h3 class="section-label">If They Ask: "Where would agents add value at Cardinal?"</h3>
            <ul>
                <li>Agents are most valuable where there are <strong>multi-step, repetitive workflows with clear decision logic</strong>. At Cardinal, think of order exception handling — an agent could automatically investigate a flagged order, check inventory, verify pricing rules, and either resolve it or escalate with a full context packet. That's hours of manual work compressed into minutes, with full audit trails.</li>
                <li>The critical point is <strong>control</strong>. Enterprise agents must operate within defined guardrails — scope limits, approval gates for high-value actions, and human-in-the-loop for anything touching patient safety or regulatory compliance. I would start with <strong>supervised agents in low-risk operational workflows</strong>, prove the pattern, then carefully expand autonomy as trust builds.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Agents extend GenAI into action</mark></li>
                    <li><mark>Orchestrated, not autonomous chaos</mark></li>
                    <li><mark>Guardrails enable safe automation</mark></li>
                    <li><mark>Human accountability remains</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="technical" data-topic="tech-copilot" data-label="Copilot">
            <h3 class="section-label">Enterprise Copilot Architecture</h3>
            <ul>
                <li><strong>Copilot is interface to enterprise intelligence</strong> — a natural language layer over organizational knowledge</li>
                <li><strong>M365 Copilot:</strong> Embedded across Word, Excel, Teams, Outlook — AI in the flow of work</li>
                <li><strong>Custom Copilots:</strong> Domain-specific copilots built on enterprise data for specialized workflows</li>
                <li><strong>Copilot Studio / Agent Builder:</strong> Low-code creation of custom agents and copilot extensions</li>
            </ul>
            <h3 class="section-label">Security & Data Boundary</h3>
            <ul>
                <li><strong>Secure, grounded, enterprise-aware AI</strong> — respects data boundaries, permissions, and compliance</li>
                <li><strong>Grounding using enterprise data:</strong> Microsoft Graph, SharePoint, internal knowledge bases</li>
                <li>Data stays within tenant boundary — <strong>no training on customer data</strong></li>
                <li>Security model: <strong>existing permissions + Copilot = same access, natural language interface</strong></li>
            </ul>
            <h3 class="section-label">Adoption & Operationalization</h3>
            <ul>
                <li><strong>Embedded in flow of work</strong> — adoption is higher because it's where people already are</li>
                <li><strong>Augmentation, not replacement</strong> — Copilot amplifies human capability, doesn't replace judgment</li>
                <li>Operationalize through: <strong>usage analytics, prompt coaching, feedback loops, champion networks</strong></li>
                <li>Microsoft AI stack: <strong>Azure OpenAI + Copilot + AI Studio + Fabric</strong> — integrated enterprise platform</li>
            </ul>
            <h3 class="section-label">If They Ask: "How would you deploy Copilot at Cardinal?"</h3>
            <ul>
                <li>Copilot adoption follows the same playbook as any enterprise AI — <strong>start with high-value personas, not a broad rollout</strong>. I'd identify 3–5 roles where Copilot delivers immediate productivity gains — supply chain planners summarizing exception reports, finance teams analyzing contracts, customer service generating grounded responses. Measure usage and value for 90 days, then expand based on data.</li>
                <li>The enterprise deployment model requires <strong>data hygiene first</strong> — Copilot is only as good as the data in SharePoint, Teams, and Microsoft Graph. I'd work with data governance to ensure content is organized, permissioned correctly, and free of stale or sensitive data before broad enablement. Security is non-negotiable — existing permissions carry through, so the <strong>permissioning model must be tight before Copilot amplifies access</strong>.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Copilot is interface to enterprise intelligence</mark></li>
                    <li><mark>Secure, grounded, enterprise-aware AI</mark></li>
                    <li><mark>Augmentation, not replacement</mark></li>
                    <li><mark>Embedded in flow of work</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="technical" data-topic="tech-platform" data-label="Platform">
            <h3 class="section-label">End-to-End Enterprise AI Architecture</h3>
            <ul>
                <li><strong>Platform, not point solutions</strong> — build once, deploy many; avoid per-project silos</li>
                <li>Architecture stack: <strong>Data platform → Models → Apps → Governance → Monitoring</strong></li>
                <li><strong>AI factory model:</strong> Centralized platform that produces AI capabilities for the entire enterprise</li>
                <li><strong>Reusable capabilities compound value</strong> — shared embeddings, common APIs, standard evaluation frameworks</li>
            </ul>
            <h3 class="section-label">Data Foundation & Platform Design</h3>
            <ul>
                <li><strong>Data foundation is non-negotiable</strong> — AI is only as good as the data it runs on</li>
                <li>Platform vs project: <strong>projects solve one problem; platforms enable hundreds</strong></li>
                <li>Data architecture: <strong>lakehouse, feature stores, knowledge graphs, vector stores</strong></li>
                <li>Design for: <strong>multi-tenancy, self-service, governed access, cost transparency</strong></li>
            </ul>
            <h3 class="section-label">Scaling Across Enterprise</h3>
            <ul>
                <li><strong>Enterprise-scale architecture</strong> — built for throughput, reliability, and security from day one</li>
                <li><strong>MLOps / GenAIOps:</strong> Automated pipelines, model registry, deployment orchestration, A/B testing</li>
                <li>Scale through: <strong>standardization, templates, accelerators, and platform teams</strong></li>
                <li>Governance built into platform — <strong>not bolted on after the fact</strong></li>
            </ul>
            <h3 class="section-label">If They Ask: "How would you design Cardinal's AI platform?"</h3>
            <ul>
                <li>I'd design the platform in layers: <strong>data foundation → model services → application layer → governance → observability</strong>. The data foundation is most critical at Cardinal — supply chain, clinical, and financial data needs to be unified, governed, and AI-ready. On top of that, shared model services (inference APIs, embedding pipelines, prompt management) so every business unit builds on the same substrate instead of creating silos.</li>
                <li>Given Cardinal's GCP footprint, I'd leverage <strong>Vertex AI and BigQuery as the backbone</strong>, with flexibility for Azure OpenAI or other model providers where needed. The platform team's job is making it <strong>easy for domain teams to build, deploy, and monitor AI</strong> — self-service with guardrails. The ROI of a platform is exponential: the first use case might cost X, but the tenth costs X/10 because the infrastructure, patterns, and governance are already in place.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Platform, not point solutions</mark></li>
                    <li><mark>AI factory model</mark></li>
                    <li><mark>Reusable capabilities compound value</mark></li>
                    <li><mark>Enterprise-scale architecture</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="technical" data-topic="tech-lifecycle" data-label="Lifecycle">
            <h3 class="section-label">Production Lifecycle & Operations</h3>
            <ul>
                <li><strong>Production-grade AI</strong> — every model in production has an owner, a monitor, and a kill switch</li>
                <li><strong>Lifecycle ownership:</strong> data → model → deploy → monitor → retrain — end-to-end accountability</li>
                <li><strong>MLOps + GenAIOps:</strong> CI/CD for ML, automated testing, feature stores, model registry, prompt versioning</li>
                <li>Build <strong>production pipelines, not notebook prototypes</strong></li>
            </ul>
            <h3 class="section-label">Monitoring, Drift & Reliability</h3>
            <ul>
                <li><strong>Monitor, measure, improve</strong> — model drift, data drift, performance degradation, cost tracking</li>
                <li><strong>Retraining:</strong> Automated triggers, champion-challenger, A/B testing in production</li>
                <li>Observability: <strong>latency, accuracy, cost per inference, user satisfaction</strong></li>
                <li>Production stability = <strong>enterprise trust</strong></li>
            </ul>
            <h3 class="section-label">Governance & Cost</h3>
            <ul>
                <li>Governance in lifecycle: <strong>bias checks, compliance gates, audit trails at every stage</strong></li>
                <li>Performance & cost tradeoffs: <strong>GPU optimization, inference cost tracking, cloud spend governance</strong></li>
                <li><strong>Sustained value over time</strong> — continuous improvement, not deploy-and-forget</li>
            </ul>
            <h3 class="section-label">If They Ask: "How do you ensure models stay reliable in production?"</h3>
            <ul>
                <li>Production AI requires the <strong>same operational rigor as any mission-critical system</strong>. Every model has an owner, a monitoring dashboard, defined SLAs, and automated alerting for drift, performance degradation, or cost anomalies. I implement champion-challenger frameworks so new model versions are validated against production baselines before they replace anything.</li>
                <li>In healthcare supply chain, <strong>reliability has patient safety implications</strong>. If a demand forecasting model drifts and causes a stockout of critical medications, that's not a technical problem — it's a patient impact problem. That's why I treat model lifecycle with the same discipline as software production systems: <strong>CI/CD, automated testing, rollback capability, and 24/7 monitoring</strong>.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Production-grade AI</mark></li>
                    <li><mark>Lifecycle ownership</mark></li>
                    <li><mark>Monitor, measure, improve</mark></li>
                    <li><mark>Sustained value over time</mark></li>
                </ul>
            </div>
        </article>

        <!-- ═══════════════════════════════════
             TAB 6: BEHAVIORAL
             ═══════════════════════════════════ -->

        <article class="topic-content" data-section="behavioral" data-topic="beh-transformation" data-label="Transformation">
            <h3 class="section-label">Leading Enterprise AI Transformation</h3>
            <ul>
                <li>Transformation is <strong>organizational, not just technical</strong> — technology is 20%, people and process are 80%</li>
                <li>Build alignment through <strong>shared vision, clear milestones, and visible progress</strong></li>
                <li>Scale impact by <strong>building capability, not dependency</strong> — the goal is self-sustaining AI maturity</li>
                <li>Transformation requires <strong>patience and persistence</strong> — enterprise change is measured in quarters, not sprints</li>
            </ul>
            <h3 class="section-label">If They Ask: "Tell me about a transformation you led"</h3>
            <ul>
                <li>At McKesson, I inherited a landscape where AI existed in <strong>pockets — fragmented, ungoverned, and disconnected from business outcomes</strong>. The mandate was to turn that into structured enterprise AI capability. I started by aligning executive leadership around a shared vision, then stood up a hub-and-spoke CoE with governance by design. Within 6 months, we had 3 high-value supply chain use cases in production, a governance framework adopted across the enterprise, and a clear pipeline of next initiatives — all with measurable margin impact.</li>
                <li>The hardest part wasn't the technology — it was <strong>shifting the organizational mindset</strong> from "AI is a tech project" to "AI is a business capability." That required persistent executive alignment, visible wins, and building trust through governance. Transformation is a marathon, but you need sprint-speed early wins to keep momentum.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>People and process over technology</mark></li>
                    <li><mark>Shared vision, clear milestones</mark></li>
                    <li><mark>Build capability, not dependency</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="behavioral" data-topic="beh-failure" data-label="Failure">
            <h3 class="section-label">Failed Initiatives & Lessons</h3>
            <ul>
                <li><strong>Over-scoped initiative:</strong> Tried to boil the ocean on first enterprise deployment — learned to start narrow and scale</li>
                <li><strong>Tech without change mgmt:</strong> Deployed excellent model with zero adoption — learned that change management is not optional</li>
                <li><strong>Governance too late:</strong> Built fast, hit compliance wall — now governance is day-one, not afterthought</li>
                <li><strong>Vendor dependency:</strong> Over-relied on vendor solution — learned to retain core IP and capability internally</li>
            </ul>
            <h3 class="section-label">Course Correction</h3>
            <ul>
                <li>Recognize failure <strong>early and act decisively</strong> — don't let sunk cost drive decisions</li>
                <li>Communicate transparently — <strong>trust is built through honesty, not spin</strong></li>
                <li>Extract the lesson, <strong>apply it systematically</strong> — one failure should prevent ten</li>
            </ul>
            <h3 class="section-label">If They Ask: "What's your biggest failure?"</h3>
            <ul>
                <li>Early in one engagement, I sponsored an ambitious enterprise AI initiative that tried to solve too many problems at once — <strong>demand forecasting, inventory optimization, and routing all in one deployment</strong>. The technology worked, but we overwhelmed the operational teams. Adoption was near zero because we didn't invest in change management, and the scope made it impossible to show clear, focused value. I learned that <strong>you have to earn the right to scale</strong> by delivering narrow, undeniable wins first.</li>
                <li>The course correction was decisive: <strong>scoped down to one use case, one persona, one measurable outcome</strong>. Delivered value in 60 days, built trust, then expanded. That lesson now shapes how I approach every new initiative — start narrow, prove value, then scale with confidence. Governance was also weak in that first attempt, which is why I now build it in from day one.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Learn fast, correct early</mark></li>
                    <li><mark>Transparency builds trust</mark></li>
                    <li><mark>Discipline over optimism</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="behavioral" data-topic="beh-influence" data-label="Influence">
            <h3 class="section-label">Influencing Executives</h3>
            <ul>
                <li>Translate technical complexity into <strong>business language</strong> — speak in outcomes, not algorithms</li>
                <li>Build trust through <strong>small wins before big asks</strong></li>
                <li>Frame AI investments in terms executives care about: <strong>revenue, cost, risk, competitive advantage</strong></li>
                <li>Prepare for <strong>"so what?"</strong> — every presentation should answer it before it's asked</li>
            </ul>
            <h3 class="section-label">Cross-Functional Alignment</h3>
            <ul>
                <li>AI is a <strong>team sport</strong> — align engineering, data, business, legal, and compliance</li>
                <li>Build <strong>shared OKRs</strong> that create joint accountability</li>
                <li>Simplify complexity — <strong>if you can't explain it simply, you don't understand it well enough</strong></li>
            </ul>
            <h3 class="section-label">If They Ask: "How do you get buy-in from the C-suite?"</h3>
            <ul>
                <li>I <strong>never lead with technology</strong>. With the CIO, I talk about platform efficiency, cost reduction, and risk. With the CFO, I talk about ROI timelines and business cases. With the CEO, I talk about competitive positioning and enterprise capability. The AI is the same — the framing changes entirely based on what they care about. At Microsoft, I worked directly with CXO leadership to frame AI investments as <strong>revenue-generating platform capabilities</strong>, not technology expenses — that shifted the conversation from cost center to strategic asset.</li>
                <li>I also believe in <strong>showing, not telling</strong>. A 5-minute live demo of an AI-powered supply chain copilot is worth more than a 50-slide deck. I bring tangible proof points — metrics, demos, user testimonials — and let the results make the case. Trust at the executive level is built through <strong>consistent delivery and transparent communication</strong>, especially when things don't go as planned.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Speak in outcomes, not algorithms</mark></li>
                    <li><mark>Small wins before big asks</mark></li>
                    <li><mark>AI is a team sport</mark></li>
                    <li><mark>Simplify complexity</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="behavioral" data-topic="beh-resistance" data-label="Resistance">
            <h3 class="section-label">Handling Adoption Resistance</h3>
            <ul>
                <li>Understand the <strong>root cause</strong> — is it fear, lack of understanding, or legitimate concern?</li>
                <li>Address <strong>emotional resistance</strong> as seriously as technical resistance</li>
                <li>Use <strong>peer influence</strong> — early adopters are more convincing than executives</li>
                <li>Make the <strong>cost of not adopting</strong> visible — show what competitors are doing</li>
            </ul>
            <h3 class="section-label">Behavioral Shift</h3>
            <ul>
                <li>Change habits through <strong>systems, not speeches</strong> — embed AI into daily workflows</li>
                <li>Celebrate and <strong>reward early adopters publicly</strong></li>
                <li>Measure behavioral change — <strong>track usage, not just availability</strong></li>
            </ul>
            <h3 class="section-label">If They Ask: "How do you change behavior at scale?"</h3>
            <ul>
                <li>Behavioral change at enterprise scale requires <strong>systems, not speeches</strong>. I embed AI into existing workflows so the path of least resistance is the AI-augmented path. At UnitedHealthcare, we didn't ask claims analysts to use a new AI tool — we embedded AI recommendations directly into their existing claims processing interface. Usage went from optional to default because <strong>the workflow made it frictionless</strong>.</li>
                <li>I also use <strong>incentive alignment and social proof</strong>. Tie KPIs to AI-augmented outcomes, publicly celebrate early adopters, and let success stories spread organically. At Cardinal, this would mean identifying champion teams in supply chain operations, equipping them with AI tools, measuring their improvement, then using that data to recruit the next wave. <strong>Peer influence beats executive mandates</strong> every time.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Address root cause of resistance</mark></li>
                    <li><mark>Systems over speeches</mark></li>
                    <li><mark>Peer influence drives adoption</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="behavioral" data-topic="beh-decision" data-label="Decision">
            <h3 class="section-label">High-Stakes Decisions</h3>
            <ul>
                <li>Decide with <strong>70% information</strong> — waiting for 100% means you're too late</li>
                <li>Distinguish between <strong>reversible and irreversible decisions</strong> — speed matters for the former</li>
                <li>Own the decision and the outcome — <strong>accountability is non-negotiable</strong></li>
                <li>Document the <strong>reasoning, not just the result</strong> — future you will thank present you</li>
            </ul>
            <h3 class="section-label">Judgment Under Uncertainty</h3>
            <ul>
                <li>Use <strong>frameworks, not gut feeling</strong> — but know when to override the framework</li>
                <li>Seek <strong>diverse perspectives</strong> before deciding — avoid echo chambers</li>
                <li>Communicate decisions with <strong>conviction and context</strong> — people follow clarity</li>
            </ul>
            <h3 class="section-label">If They Ask: "Tell me about a tough decision you made"</h3>
            <ul>
                <li>I was leading an AI initiative where we'd invested significant resources into a vendor-built solution that wasn't delivering. The team was emotionally invested, the vendor relationship was important to the org, and sunk cost was real. I made the decision to <strong>sunset the vendor approach and rebuild on our own platform</strong> — it was unpopular in the short term, but within 6 months our internal solution was outperforming at a fraction of the cost. The key was <strong>presenting the data transparently</strong>, acknowledging the team's effort, and framing it as a strategic pivot, not a failure.</li>
                <li>I've learned that the best leaders <strong>make hard calls early and communicate them clearly</strong>. Waiting for perfect information means the decision makes itself — usually badly. I document my reasoning, seek diverse input before deciding, and then commit fully. People don't need perfect decisions — they need <strong>clear decisions with clear rationale</strong>.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Decide with imperfect data</mark></li>
                    <li><mark>Accountability is non-negotiable</mark></li>
                    <li><mark>Conviction and context</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="behavioral" data-topic="beh-teams" data-label="Teams">
            <h3 class="section-label">Building AI Teams</h3>
            <ul>
                <li><strong>Core roles:</strong> ML Engineers, Data Scientists, Data Engineers, ML Platform, AI Product Managers</li>
                <li><strong>Builders + Translators:</strong> Technical builders paired with business translators</li>
                <li>Hire for <strong>production mindset</strong>, not just research credentials</li>
                <li>Scalable org: <strong>pods by domain</strong> with shared platform</li>
            </ul>
            <h3 class="section-label">Culture & Leadership Development</h3>
            <ul>
                <li>Create a culture of <strong>safe experimentation</strong> — failure is learning, not punishment</li>
                <li>Grow leaders internally — <strong>promote people who ship, not just present</strong></li>
                <li>Break silos: <strong>collaboration between data, engineering, business, and compliance</strong></li>
                <li>Celebrate <strong>business outcomes</strong>, not just technical achievements</li>
            </ul>
            <h3 class="section-label">If They Ask: "How would you build the AI team at Cardinal?"</h3>
            <ul>
                <li>I'd start by <strong>assessing existing talent</strong> — Cardinal likely has strong data and analytics people who can be upskilled into AI roles. Then I'd hire strategically for gaps: <strong>ML platform engineers, applied ML scientists, and AI product managers</strong> who can translate business problems into AI solutions. I don't over-index on PhDs — I want people who can ship production AI, not just write research papers.</li>
                <li>The team structure matters: I build <strong>pods organized by domain</strong> (supply chain AI, customer AI, operations AI) sitting on top of a shared platform team. Each pod has builders and translators — technical people paired with business-facing AI product managers. Culture-wise, I foster <strong>safe experimentation with delivery accountability</strong> — try bold things, but ship reliably. I also invest in growing leaders internally — the best AI organizations promote people who deliver, not just people who present well.</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Builders + translators</mark></li>
                    <li><mark>Production mindset</mark></li>
                    <li><mark>Safe experimentation</mark></li>
                    <li><mark>Grow internal leaders</mark></li>
                </ul>
            </div>
        </article>

        <!-- ═══════════════════════════════════
             TAB 7: QUESTIONS
             ═══════════════════════════════════ -->

        <article class="topic-content" data-section="questions" data-topic="questions-core" data-label="Core">
            <h3 class="section-label">Culture & Leadership</h3>
            <ul>
                <li>How would you describe the <strong>culture across Cardinal's digital and AI teams</strong>, and what leadership styles tend to be most effective here?</li>
            </ul>
            <h3 class="section-label">Current State & Opportunity</h3>
            <ul>
                <li>What is <strong>working particularly well</strong> across the IT and AI organization today, and where do you see the <strong>biggest opportunity for improvement or acceleration</strong>?</li>
            </ul>
            <h3 class="section-label">Success Definition</h3>
            <ul>
                <li>If we were having this conversation <strong>a year from now</strong>, what would <strong>success in this role</strong> look like?</li>
            </ul>
            <h3 class="section-label">Most Critical Challenge</h3>
            <ul>
                <li>What is the <strong>most important problem</strong> this role needs to address <strong>early on</strong>?</li>
            </ul>
            <h3 class="section-label">Strategic Impact</h3>
            <ul>
                <li>From your perspective, how could this role help position <strong>Cardinal Health as a leader</strong> in responsible, enterprise-scale AI adoption across <strong>healthcare</strong>?</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Culture & leadership fit</mark></li>
                    <li><mark>Biggest opportunity</mark></li>
                    <li><mark>Year-one success</mark></li>
                    <li><mark>Early critical challenge</mark></li>
                    <li><mark>Strategic positioning</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="questions" data-topic="questions-closing" data-label="Closing">
            <h3 class="section-label">Optional Closing Question</h3>
            <ul>
                <li>Is there anything from our discussion you would like me to <strong>expand on or clarify further</strong>?</li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Show openness & confidence</mark></li>
                    <li><mark>Leave the door open</mark></li>
                </ul>
            </div>
        </article>

        <!-- ═══════════════════════════════════
             TAB 8: COMP
             ═══════════════════════════════════ -->

        <article class="topic-content" data-section="comp" data-topic="comp-current" data-label="Current">
            <h3 class="section-label">Quick Facts (Internal Reference)</h3>
            <ul>
                <li><strong>Base:</strong> ~225K</li>
                <li><strong>Incentives:</strong> Performance-based (RBI + CBI)</li>
                <li><strong>Equity forfeiture:</strong> ~300K unvested</li>
            </ul>
            <h3 class="section-label">If Asked: "What are you making today?"</h3>
            <ul>
                <li>My compensation includes <strong>base in the mid-200s</strong> plus performance incentives and long-term equity</li>
                <li>A meaningful portion is <strong>equity-based</strong> and tied to long-term performance</li>
            </ul>
            <h3 class="section-label">If Asked About Forfeiture</h3>
            <ul>
                <li>Transition would involve <strong>forfeiting unvested equity</strong></li>
                <li>I look at <strong>total alignment, not just base</strong></li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Mid-200s base + incentives</mark></li>
                    <li><mark>Equity-based, long-term</mark></li>
                    <li><mark>Total alignment</mark></li>
                </ul>
            </div>
        </article>

        <article class="topic-content" data-section="comp" data-topic="comp-expect" data-label="Expectations">
            <h3 class="section-label">If Asked: "What are your expectations?"</h3>
            <ul>
                <li>I'm looking for an <strong>executive-level package</strong> aligned with scope and impact</li>
                <li>I focus on <strong>total value</strong>, including long-term incentives</li>
                <li><strong>Alignment matters more than rigidity</strong></li>
            </ul>
            <div class="phrase-block">
                <h4>Key Phrases</h4>
                <ul>
                    <li><mark>Total value alignment</mark></li>
                    <li><mark>Executive-level package</mark></li>
                    <li><mark>Long-term incentives</mark></li>
                    <li><mark>Holistic view</mark></li>
                    <li><mark>Competitive and fair</mark></li>
                    <li><mark>Structured for performance</mark></li>
                </ul>
            </div>
        </article>

    </main>

    <!-- Search Results Overlay -->
    <div id="searchOverlay" class="hidden">
        <div id="searchResults"></div>
    </div>

    <script src="app.js"></script>
</body>
</html>
